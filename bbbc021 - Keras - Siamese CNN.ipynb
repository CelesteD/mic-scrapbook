{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of <i>Learning a similarity metric discriminatively, with application to face verification</i>, by Sumit Chopra, Raia Hadsell and Yann LeCun (2005).  Cited by 405 at the time of this writing (21 July 2016). <br><br>\n",
    "\n",
    "Code structure borrowed from the Keras examples: https://github.com/fchollet/keras/tree/master/examples\n",
    " \n",
    "The best performing Siamese ConvNet architecture is: C1, S2, C3, S4, C5, F6. C is a convolution layer, S is a \"sub-sampling\" (probably a.k.a. pooling?) layer, F is a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fd019376bad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMerge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_model'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, Model\n",
    "#from keras.models import load_model. Why can't this import?\n",
    "from keras.layers import Dense, Dropout, Activation, Merge, Embedding, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Layer, Input\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import skynet.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i+1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_base_network(input_dim):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(128, input_shape=(input_dim,), activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    seq.add(Dropout(0.1))\n",
    "    seq.add(Dense(128, activation='relu'))\n",
    "    return seq\n",
    "\n",
    "\n",
    "def create_base_convnet(input_img_shape, verbose=False):\n",
    "    cnn = Sequential()\n",
    "    #C1\n",
    "    cnn.add(Convolution2D(15, 7, 7, \n",
    "                          activation='relu', \n",
    "                          border_mode='same',\n",
    "                          input_shape=input_img_shape))\n",
    "    if verbose:\n",
    "        print(\"C1 shape: \", cnn.output_shape)\n",
    "\n",
    "    #S2\n",
    "    cnn.add(MaxPooling2D((2, 2), border_mode='same'))\n",
    "    if verbose:\n",
    "        print(\"S2 shape: \", cnn.output_shape)\n",
    "\n",
    "    #C3\n",
    "    cnn.add(Convolution2D(45, 6, 6, \n",
    "                          activation='relu', \n",
    "                          border_mode='same'))\n",
    "    if verbose:\n",
    "        print(\"C3 shape: \", cnn.output_shape)\n",
    "\n",
    "    #S4\n",
    "    cnn.add(MaxPooling2D((4,3), border_mode='same'))\n",
    "    if verbose:\n",
    "        print(\"S4 shape: \", cnn.output_shape)\n",
    "    #C5\n",
    "    cnn.add(Convolution2D(250, 5, 5,\n",
    "                          activation='relu',\n",
    "                          border_mode='same'))\n",
    "    if verbose:\n",
    "        print(\"C5 shape: \", cnn.output_shape)\n",
    "    #F6\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(50))\n",
    "    if verbose:\n",
    "        print(\"F6 shape: \", cnn.output_shape)\n",
    "\n",
    "    return cnn\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Stats\n",
      "----------\n",
      "x_train.shape = (76960, 3, 30, 30)\n",
      "x_test.shape = (19240, 3, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "# Load bbbc021 patch data\n",
    "# Warning: these are MOA labels!\n",
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "y_train = np.load('label_train.npy')\n",
    "y_test = np.load('label_test.npy')\n",
    "\n",
    "n_trg, patchlen, patchlen, ch = x_train.shape\n",
    "n_test, patchlen, patchlen, ch = x_test.shape\n",
    "\n",
    "x_train = utils.swap_image_format_list(x_train)\n",
    "x_test = utils.swap_image_format_list(x_test)\n",
    "\n",
    "print(\"Data Stats\")\n",
    "print(\"-\"*10)\n",
    "print(\"x_train.shape = %s\" % (x_train.shape,))\n",
    "print(\"x_test.shape = %s\" % (x_test.shape,))\n",
    "\n",
    "labels = list(set(y_train))\n",
    "\n",
    "#Convert y_labels from string to integer categories\n",
    "y_train2 = utils.my_one_hot_index(y_train, labels)\n",
    "y_test2 = utils.my_one_hot_index(y_test, labels)\n",
    "\n",
    "# Set params\n",
    "nb_classes = 13\n",
    "input_img_shape = (3, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training pairs:  23980\n",
      "No. of testing pairs:  5980\n"
     ]
    }
   ],
   "source": [
    "# Generate genuine and imposter input pairs\n",
    "digit_indices = [np.where(y_train2 == i)[0] for i in range(10)]\n",
    "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_test2 == i)[0] for i in range(10)]\n",
    "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "print(\"No. of training pairs: \", len(tr_pairs))\n",
    "print(\"No. of testing pairs: \", len(te_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# network definition\n",
    "input_a = Input(shape=input_img_shape)\n",
    "input_b = Input(shape=input_img_shape)\n",
    "\n",
    "base_network = create_base_convnet(input_img_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model(input=[input_a, input_b], output=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23980 samples, validate on 5980 samples\n",
      "Epoch 1/50\n",
      "23980/23980 [==============================] - 177s - loss: 0.1394 - val_loss: 0.1585\n",
      "Epoch 2/50\n",
      "23980/23980 [==============================] - 161s - loss: 0.1364 - val_loss: 0.1564\n",
      "Epoch 3/50\n",
      "23980/23980 [==============================] - 163s - loss: 0.1360 - val_loss: 0.1732\n",
      "Epoch 4/50\n",
      "23980/23980 [==============================] - 164s - loss: 0.1339 - val_loss: 0.1728\n",
      "Epoch 5/50\n",
      "23980/23980 [==============================] - 164s - loss: 0.1315 - val_loss: 0.1468\n",
      "Epoch 6/50\n",
      "23980/23980 [==============================] - 165s - loss: 0.1313 - val_loss: 0.1477\n",
      "Epoch 7/50\n",
      "23980/23980 [==============================] - 167s - loss: 0.1296 - val_loss: 0.1568\n",
      "Epoch 8/50\n",
      "23980/23980 [==============================] - 178s - loss: 0.1273 - val_loss: 0.1616\n",
      "Epoch 9/50\n",
      "23980/23980 [==============================] - 192s - loss: 0.1269 - val_loss: 0.1623\n",
      "Epoch 10/50\n",
      "23980/23980 [==============================] - 186s - loss: 0.1257 - val_loss: 0.1613\n",
      "Epoch 11/50\n",
      "23980/23980 [==============================] - 213s - loss: 0.1245 - val_loss: 0.1728\n",
      "Epoch 12/50\n",
      "23980/23980 [==============================] - 223s - loss: 0.1252 - val_loss: 0.1526\n",
      "Epoch 13/50\n",
      "23980/23980 [==============================] - 208s - loss: 0.1218 - val_loss: 0.1523\n",
      "Epoch 14/50\n",
      "23980/23980 [==============================] - 192s - loss: 0.1204 - val_loss: 0.1606\n",
      "Epoch 15/50\n",
      "23980/23980 [==============================] - 209s - loss: 0.1192 - val_loss: 0.1694\n",
      "Epoch 16/50\n",
      "23980/23980 [==============================] - 195s - loss: 0.1213 - val_loss: 0.1586\n",
      "Epoch 17/50\n",
      "23980/23980 [==============================] - 197s - loss: 0.1189 - val_loss: 0.1659\n",
      "Epoch 18/50\n",
      "23980/23980 [==============================] - 199s - loss: 0.1170 - val_loss: 0.1623\n",
      "Epoch 19/50\n",
      "23980/23980 [==============================] - 197s - loss: 0.1170 - val_loss: 0.1644\n",
      "Epoch 20/50\n",
      "23980/23980 [==============================] - 204s - loss: 0.1164 - val_loss: 0.1627\n",
      "Epoch 21/50\n",
      "23980/23980 [==============================] - 189s - loss: 0.1162 - val_loss: 0.1557\n",
      "Epoch 22/50\n",
      "23980/23980 [==============================] - 185s - loss: 0.1154 - val_loss: 0.1541\n",
      "Epoch 23/50\n",
      "23980/23980 [==============================] - 224s - loss: 0.1150 - val_loss: 0.1657\n",
      "Epoch 24/50\n",
      "23980/23980 [==============================] - 260s - loss: 0.1145 - val_loss: 0.1733\n",
      "Epoch 25/50\n",
      "23980/23980 [==============================] - 254s - loss: 0.1137 - val_loss: 0.1699\n",
      "Epoch 26/50\n",
      "23980/23980 [==============================] - 257s - loss: 0.1133 - val_loss: 0.1609\n",
      "Epoch 27/50\n",
      "23980/23980 [==============================] - 263s - loss: 0.1128 - val_loss: 0.1662\n",
      "Epoch 28/50\n",
      "23980/23980 [==============================] - 256s - loss: 0.1129 - val_loss: 0.1682\n",
      "Epoch 29/50\n",
      "23980/23980 [==============================] - 262s - loss: 0.1141 - val_loss: 0.1641\n",
      "Epoch 30/50\n",
      "23980/23980 [==============================] - 255s - loss: 0.1125 - val_loss: 0.1691\n",
      "Epoch 31/50\n",
      "23980/23980 [==============================] - 254s - loss: 0.1118 - val_loss: 0.1622\n",
      "Epoch 32/50\n",
      "23980/23980 [==============================] - 253s - loss: 0.1108 - val_loss: 0.1665\n",
      "Epoch 33/50\n",
      "23980/23980 [==============================] - 259s - loss: 0.1108 - val_loss: 0.1677\n",
      "Epoch 34/50\n",
      "23980/23980 [==============================] - 257s - loss: 0.1097 - val_loss: 0.1655\n",
      "Epoch 35/50\n",
      "23980/23980 [==============================] - 257s - loss: 0.1091 - val_loss: 0.1793\n",
      "Epoch 36/50\n",
      "23980/23980 [==============================] - 256s - loss: 0.1089 - val_loss: 0.1722\n",
      "Epoch 37/50\n",
      "23980/23980 [==============================] - 251s - loss: 0.1090 - val_loss: 0.1689\n",
      "Epoch 38/50\n",
      "23980/23980 [==============================] - 255s - loss: 0.1090 - val_loss: 0.1621\n",
      "Epoch 39/50\n",
      "23980/23980 [==============================] - 254s - loss: 0.1071 - val_loss: 0.1708\n",
      "Epoch 40/50\n",
      "23980/23980 [==============================] - 253s - loss: 0.1076 - val_loss: 0.1644\n",
      "Epoch 41/50\n",
      "23980/23980 [==============================] - 249s - loss: 0.1078 - val_loss: 0.1920\n",
      "Epoch 42/50\n",
      "23980/23980 [==============================] - 258s - loss: 0.1085 - val_loss: 0.1668\n",
      "Epoch 43/50\n",
      "23980/23980 [==============================] - 258s - loss: 0.1080 - val_loss: 0.1658\n",
      "Epoch 44/50\n",
      "23980/23980 [==============================] - 254s - loss: 0.1074 - val_loss: 0.1713\n",
      "Epoch 45/50\n",
      "23980/23980 [==============================] - 225s - loss: 0.1058 - val_loss: 0.1711\n",
      "Epoch 46/50\n",
      "23980/23980 [==============================] - 200s - loss: 0.1052 - val_loss: 0.1644\n",
      "Epoch 47/50\n",
      "23980/23980 [==============================] - 168s - loss: 0.1055 - val_loss: 0.1713\n",
      "Epoch 48/50\n",
      "23980/23980 [==============================] - 168s - loss: 0.1052 - val_loss: 0.1673\n",
      "Epoch 49/50\n",
      "23980/23980 [==============================] - 168s - loss: 0.1039 - val_loss: 0.1932\n",
      "Epoch 50/50\n",
      "23980/23980 [==============================] - 2497s - loss: 0.1038 - val_loss: 0.1820\n",
      "Done in 3:39:42\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "nb_epoch=50\n",
    "batch_size = 32\n",
    "t0 = time.time()\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], \n",
    "          tr_y,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "dt = time.time() - t0\n",
    "m, s = divmod(dt, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print(\"Done in %d:%02d:%02d\" % (h, m, s))\n",
    "# batch_size = 128: loss ~= 8.4336, dt ~= 800s\n",
    "# batch_size = 32: val_loss ~=0.2586, dt = 944s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Accuracy on training set: 86.60%\n",
      "* Accuracy on test set: 80.58%\n"
     ]
    }
   ],
   "source": [
    "# compute final accuracy on training and test sets\n",
    "pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(pred, tr_y)\n",
    "pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(pred, te_y)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
