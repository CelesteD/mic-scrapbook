{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are patches from the bbbc021 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "\n",
    "from skimage import io, filters, util, data, img_as_float\n",
    "import microscopium as mic\n",
    "#import microscopium.features as micfeat\n",
    "import scipy\n",
    "import brewer2mpl\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, SparseCoder, sparse_encode, PCA\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, PatchExtractor, reconstruct_from_patches_2d\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuitCV\n",
    "from sklearn.datasets import make_sparse_coded_signal\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#os.getcwd()\n",
    "os.chdir(\"/Users/don/Documents/hcs\")\n",
    "sys.path.append(\"/Users/don/Documents/PyModules\")\n",
    "\n",
    "#Tell numpy to skip division by zero in broadcasting\n",
    "np.seterr(divide = 'ignore', invalid = 'ignore')\n",
    "\n",
    "import skynet.pipeline\n",
    "import skynet.utils\n",
    "import skynet.rsnn_x as rsnn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an RSNN with a bunch of patches and their MOA labels. IO details in bbbc021IO.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Stats\n",
      "----------\n",
      "x_train.shape = (76960, 30, 30, 3)\n",
      "x_test.shape = (19240, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "labels_train = np.load('label_train.npy')\n",
    "labels_test = np.load('label_test.npy')\n",
    "\n",
    "n_trg, patchlen, patchlen, ch = x_train.shape\n",
    "n_test, patchlen, patchlen, ch = x_test.shape\n",
    "\n",
    "print(\"Data Stats\")\n",
    "print(\"-\"*10)\n",
    "print(\"x_train.shape = %s\" % (x_train.shape,))\n",
    "print(\"x_test.shape = %s\" % (x_test.shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll flatten the data by unravelling each patch, concatenating the colour channels end to end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76960, 2700)\n"
     ]
    }
   ],
   "source": [
    "patches_train = []\n",
    "patches_test = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    patch_lin = x_train[i].reshape(patchlen*patchlen*ch)\n",
    "    patches_train.append(patch_lin)\n",
    "    \n",
    "for i in range(len(x_test)):\n",
    "    patch_lin = x_test[i].reshape(patchlen*patchlen*ch)\n",
    "    patches_test.append(patch_lin)\n",
    "\n",
    "patches_train = np.array(patches_train)\n",
    "patches_test = np.array(patches_test)\n",
    "\n",
    "#Normalization dummy code\n",
    "\"\"\"mydata = mydata.reshape(mydata.shape[0],-1)\n",
    "print(\"Data shape after reshape: %s\" % (mydata.shape,))\n",
    "\n",
    "#Normalization\n",
    "mydata -= np.mean(mydata, axis = 0)\n",
    "mydata /= np.std(mydata, axis = 0)\n",
    "mydata[np.isnan(mydata)] = 0.0\"\"\"\n",
    "\n",
    "#To save space\n",
    "del x_train\n",
    "del x_test\n",
    "\n",
    "#Final printout checks\n",
    "print(patches_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's convert the labels to indices. Due to the way that the images were extracted, there will never be any labels in the training set that isn't present in the testing set, or vice versa. Note that train_rfciw() accepts indices just as integers; it'll do the one-hot encoding for you.<br><br>We'll see that there are 13 labels in all. There were originally 103 MOA labels; I suppose that those without compound-concentration representations were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "(76960,)\n",
      "(19240,)\n"
     ]
    }
   ],
   "source": [
    "labels_ref = list(set(labels_train))\n",
    "print(len(labels_ref))\n",
    "\n",
    "labels_train2 = skynet.utils.my_one_hot(labels_train, labels_ref)\n",
    "labels_test2 = skynet.utils.my_one_hot(labels_test, labels_ref)\n",
    "\n",
    "#print(labels_train2.shape)\n",
    "#print(labels_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      "------------\n",
      "n_images = 76960\n",
      "img size = 2700\n",
      "side length = 30.0\n",
      "n_hidden = 5000\n",
      "\n",
      "rf.shape = (5000, 2700)\n",
      "\n",
      "GENERATING RANDOM WEIGHTS\n",
      "--------------------------\n",
      "w_random.shape = (5000, 2701)\n",
      "\n",
      "ACTIVATING INPUT DATA\n",
      "--------------------\n",
      "A = f(w_random * X.T) = f(Z)\n",
      "w_random.shape = (5000, 2701)\n",
      "X.shape = (76960, 2701)\n",
      "activations.shape = (5000, 76960)\n",
      "\n",
      "Done in 0:03:50\n",
      "w_out.shape = (5000, 13)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "w_random, w_out = rsnn2.train_rfciw(patches_train, \n",
    "                                    labels_train2, \n",
    "                                    n_ch = 3,\n",
    "                                    n_hidden = 5000, verbose=True)\n",
    "\n",
    "dt = time.time() - t0\n",
    "m, s = divmod(dt, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print(\"Done in %d:%02d:%02d\" % (h, m, s))\n",
    "print(\"w_out.shape = %s\" % (w_out.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62281704781704783"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy\n",
    "predict_out = rsnn2.test_accuracy(patches_test,labels_test2,w_random, w_out)\n",
    "predict_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a fairly impressive 62.28% prediction accuracy. For posterity, this was done with 5000 hidden units, and took 3 mins 50s. <br>\n",
    "\n",
    "Now let's test our weights against randomly-generated labels, to establish a baseline accuracy of randomly guessing labels. Also note that since a couple of the labels ('DMSO') is vastly overrepresented, in the data set, we could also say that \"all samples belong to DMSO\" and still be correct about 37% of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get a DF of the labels\n",
    "labels_ref = list(set(labels_train))\n",
    "\n",
    "df = []\n",
    "for i in range(len(labels_ref)):\n",
    "    df.append(list(labels_train).count(labels_ref[i]))\n",
    "\n",
    "df = np.array(df)\n",
    "total = np.sum(df)\n",
    "df = df/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0done in 10.99s\n",
      "1done in 11.29s\n",
      "2done in 13.45s\n",
      "3done in 12.45s\n",
      "4done in 11.40s\n",
      "5done in 10.89s\n",
      "6done in 11.24s\n",
      "7done in 11.14s\n",
      "8done in 10.98s\n",
      "9done in 11.52s\n",
      "10done in 12.22s\n",
      "11done in 11.01s\n",
      "12done in 10.99s\n",
      "13done in 11.54s\n",
      "14done in 11.74s\n",
      "15done in 12.64s\n",
      "16done in 12.37s\n",
      "17done in 11.26s\n",
      "18done in 12.98s\n",
      "19done in 11.53s\n",
      "20done in 12.31s\n",
      "21done in 11.49s\n",
      "22done in 11.43s\n",
      "23done in 10.96s\n",
      "24done in 11.66s\n",
      "25done in 11.41s\n",
      "26done in 13.13s\n",
      "27done in 14.38s\n",
      "28done in 12.35s\n",
      "29done in 12.66s\n",
      "30done in 12.21s\n",
      "31done in 14.41s\n",
      "32done in 12.57s\n",
      "33done in 12.53s\n",
      "34done in 12.37s\n",
      "35done in 11.77s\n",
      "36done in 12.21s\n",
      "37done in 12.15s\n",
      "38done in 12.49s\n",
      "39done in 15.28s\n",
      "40done in 15.93s\n",
      "41done in 15.83s\n",
      "42done in 12.54s\n",
      "43done in 12.18s\n",
      "44done in 11.00s\n",
      "45done in 16.09s\n",
      "46done in 15.04s\n",
      "47done in 14.92s\n",
      "48done in 12.67s\n",
      "49done in 11.82s\n"
     ]
    }
   ],
   "source": [
    "#No. of permutations\n",
    "B = 50\n",
    "\n",
    "bootstrapped = np.zeros(B)\n",
    "for i in range(B):\n",
    "    t0 = time.time()\n",
    "    print(Iteration i , end = \"\")\n",
    "    labels_nonsense = np.random.choice(len(labels_ref),\n",
    "                                  len(labels_test2),\n",
    "                                 p=df)\n",
    "    bootstrapped[i] = rsnn2.test_accuracy(patches_test,labels_nonsense,w_random, w_out)\n",
    "    print(\"done in %.2fs\" % (time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.348406444906 0.00396717247323\n"
     ]
    }
   ],
   "source": [
    "mu = np.mean(bootstrapped)\n",
    "sigma = np.std(bootstrapped)\n",
    "print(mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Random guessing gives us a 34.84% (s.d. 0.39) accuracy. Further analysis to come: a k-fold CV of some kind? Which classes have the highest classification accuracy (that is, is this correlated with the relative proportions of labels in the training data)?<br><br>Technical note: generating random numbers seems to take up the bulk of running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
